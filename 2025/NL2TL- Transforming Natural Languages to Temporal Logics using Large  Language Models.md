文提出了一种基于大语言模型的自然语言到时序逻辑（NL→TL）转换框架，通过**语义解耦**和**分层转换**解决传统方法依赖领域知识的问题。核心创新在于将输入指令**抽象化处理**：首先用GPT-3识别原子命题（如"避开障碍物"→`prop_1`），生成仅保留逻辑结构的中间表示（如"执行prop_1并最终执行prop_2"）；随后通过微调T5模型将抽象指令转换为通用时序逻辑公式（如`(globally prop_1) and (finally prop_2)`），最后重构为完整STL表达式。该方法在机器人、工业控制等5个领域测试中达到**97.5%准确率**，比GPT-4直接生成高20%，且仅需200个领域样本微调即可实现跨领域泛化，显著降低人工标注成本90%，为自然语言编程提供了可扩展的新范式。
